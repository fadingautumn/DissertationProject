text = """Буря мглою небо кроет,
Вихри снежные крутя;
То, как зверь, она завоет,
То заплачет, как дитя,
То по кровле обветшалой
Вдруг соломой зашумит,
То, как путник запоздалый,
К нам в окошко застучит."""

dictmeter = {
    '010101': 'Трёхстопный ямб',
    '01010101': 'Четырёхстопный ямб',
    '0101010101': 'Пятистопный ямб',
    '010101010101': 'Шестистопный ямб',
    '01010101010101': 'Семистопный ямб',
    '0101010101010101': 'Восьмистопный ямб',
    '101010': 'Трёхстопный хорей',
    '10101010': 'Четырёхстопный хорей',
    '11101010': 'Четырёхстопный хорей',
    '1010001': 'Четырёхстопный хорей',
    '1010101': 'Четырёхстопный хорей',
    '1010101010': 'Пятистопный хорей',
    '101010101010': 'Шестистопный хорей',
    '10101010101010': 'Семистопный хорей',
    '1010101010101010': 'Восьмистопный хорей',
    '100100100': 'Трёхстопный дактиль',
    '100100100100': 'Четырёхстопный дактиль',
    '100100100100100': 'Пятистопный дактиль',
    '100100100100100100': 'Шестистопный дактиль',
    '010010010': 'Трёхстопный амфибрахий',
    '010010010010': 'Четырёхстопный амфибрахий',
    '010010010010010': 'Пятистопный амфибрахий',
    '010010010010010010': 'Шестистопный амфибрахий',
    '001001001': 'Трёхстопный анапест',
    '001001001001': 'Четырёхстопный анапест',
    '001001001001001': 'Пятистопный анапест',
    '001001001001001001': 'Шестистопный анапест'
    
}

dict1 = {
    'буря': '10',
    'мглою': '10',
    'небо': '10',
    'кроет': '10',
    'вихри': '10',
    'снежные': '100',
    'крутя': '01',
    'то': '1',
    'как': '1',
    'зверь': '1',
    'она': '01',
    'завоет': '010',
    'заплачет': '010',
    'дитя': '01',
    'по': '1',
    'кровле': '10',
    'обветшалой': '0010',
    'вдруг': '1',
    'соломой': '010',
    'зашумит': '001',
    'путник': '10',
    'запоздалый': '0010',
    'к нам в': '1',
    'окошко': '010',
    'застучит': '001'
}

import re
import collections
import nltk
from nltk import word_tokenize

def line_count(x):
    lines = x.split('\n')
    all_step = []
    line_acc = ''
    for line in lines:
        cleantext = line.lower() 
        cleantext = re.sub('[^а-яА-Я]', ' ', cleantext)
        words = nltk.word_tokenize(cleantext)
        for word in words:
            if word in dict1:
                line_acc += dict1[word]
            if line_acc in dictmeter:
                all_step.append(dictmeter[line_acc])
        return all_step

line_count(text)
